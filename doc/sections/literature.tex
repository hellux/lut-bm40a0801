\documentclass[doc/report.tex]{subfiles}

% Present relevant methods and approaches from scientific publications.

\begin{document}

\section{Literature review}
The existing work and literature on object recognition is extensive. The task
of classifying images based on the content is here approached with two
perspectives. Identify regions of the picture as a representation of some
object. The other is the comparing technical features of picture without
identification of objects in the picture. Such information is accessible from
the picture. A database of objects in the training set is needed for the other.

For classifying pictures based on objects they represent it is often needed to
normalize intensity information in them. Histogram equalization brings
properties of the objects more accessible and more independent from properties
of images.

To classify or cluster and classify images a method of comparing the vector of
image data with other vectors is sometimes used with neural net solutions like
CNN. To provide valid results, they are trained with a set of pictures. The net
is given response about the correctness of the answer for each of the training
pictures, and each picture is potentially used many times in the random order.
Values of features and regions evolve in the net without user directly
interfering. Other methods require more explicit information mining from the
picture.

\subsection{Feature extraction and region processing}
A region, an area in the picture, is sometimes an identifiable object in the
picture. Even if it is the goal to classify the main object of the picture,
sub-objects are often the handle for the class. For example, with the
information of the round objects the task of classification of the main object
is simplified. Convolutional networks do the process sometimes implicitly.

Generally, classification / training phase is faster or more accurate, if some
feature extraction is done to make the process specific for the task.

The color information, often Lab, grayscale intensities, statistical and
frequency level information are examples of features of the whole picture. They
are used for region analysis also.

To get regions or image segments it is the histograms first. From intensity
values of either color or grayscale, partitions separated from the rest, are
potential regions. A binary image is separated, outline i.e. border is
extracted. Remainder of the picture is returned to histogram and the process is
repeated.

Level sets and snakes are used to improve quality of the region. It is possible
to get watertight borderlines without noise by applying those methods.

Some candidates for the region features are convexity, cardinal line, normal
lines of cl, statistics of length of normal lines, skeleton of the region,
Area, length, width.

The boundary is one of the primary sources for the feature mining. Examples of
methods used with it are:

\begin{itemize}
    \item Chain Code, a vector of vectors describing segments of the boundary.
        With them many indicators of the region are possible. Area, height,
        width, cardinal lines and convexity are among possible results of the
        function with chain code as a parameter.
    \item Fourier descriptor, a complex valued vector about the boundary. It is
        used to identify, scale, rotate, and translate the boundary for the
        similarity measurement.
    \item Skeleton of the region. Middle lines of the region evaluated from the
        boundary. .
    \item The Hough transformation allows the search of ridges, curves and
        round or elliptical areas from the picture. Shapes and sizes are not
        limited.
    \item Morphological operators. Dilating and eroding binary images with
        different kernels. For example, to extraction of outlines or reduced
        noise from the picture. Opening and closing operations combination of
        two main processing styles
\end{itemize}

Also, the background is potentially processed as a region. The Texture
information is also used as a feature. Use morphological operators and
frequency transformations are possible solutions to create selector for the
texture.

In 2006, Herbert Bay et. al introduced SURF, a rotation-invariant point
detector and descriptor for use in object recognition.\cite{bay-surf} It showed
strong performance in comparison to previous algorithms at the time.

\subsection{Self Organizing Map}
The Self Organizing Map, SOM is a Neural Net model for dimension reduction.
From training material each picture is associated with a feature vector. Number
of pictures is the original dimension count and reduced dimension count is the
number of the classes of the pictures are representing, like cars, cats and so
on. For each class there is a weight vector in  the result space. The algorithm
starts random input vector. Euclidean distance is evaluated to each weight
vector, and nearest is considered the closest match. Weights of the feature
dimensions of the closest weight vector are adjusted to minimize the average
distance within the group.

In SOM map space is number of weight vectors with the dimensionality of input
vectors. In image processing dimensionality of the feature space. Weight
vectors represent classes similarly to KNN-clustering. When a new vector, i.e.
image is added to the system, Euclidean distances to weight vectors are
evaluated. Weights of the closest class are adjusted with a function
\eqref{eqn:som_w} to make the weight vector closer to the new vector.

\begin{equation}
    W_v(s+1) = W_v(s) + \theta(u, v, s) \cdot \alpha(s) \cdot (D(t) - W_v(s))
    \label{eqn:som_w}
\end{equation}

\begin{itemize}
    \item $W_v$: Weight vector closest to vector $v$
    \item $\theta$: Distance function giving distance from $u$ to $v$ in step
        $s$
    \item $\alpha$: Learning rate function, it gets smaller when the space size
        increases
    \item $D$: Input vector indexed with $t$
    \item $s$: step index
    \item $u$: index to best matching class vector
    \item $v$: index to a neuron in the goal space
\end{itemize}

\subsection{Convolutional Neural Networks}
% TODO intro
Several pre-trained models used in transfer learning are based on large convolutional neural networks (CNN).Its high performance and its easiness in training are two of the main factors for its popularity in Machine Vision applications.
A typical CNN consists of two parts:
\begin{enumerate}
	\item A convolutional base, composed of a stack of convolutional and pooling layers. The main goal of the convolutional base is to generate features from the image
	\item A classifier, composed of fully connected layers that seek to classify the images based on the detected features.
\end{enumerate}
An important aspect of these CNNs is that they can automatically learn hierarchical feature representations. This implies that features computed by the first layer of the CNN are very general and can be easily reused in different domains, while on the other hand the features computed by the last layer of the CNN are specific and depend on the chosen dataset and task at hand. A few of the popular pre-trained models based on CNN are described in the upcoming subsections.

\subsubsection{AlexNet}
AlexNet\cite{Alex}, which has been trained over a million images in the
ImageNet dataset, is one of the most commonly used pretrained network for
transfer learning. It can classify images into 1000 different categories such
as pencil, coffee mug, keyboard etc. and outputs the probability for each of
the object categories. The neural network has about 60 million parameters and
650,000 neurons and consists of five convolutional layers which are followed by
max-pooling layers and three fully-connected layers. To reduce overfitting in
the fully-connected layers the authors had  employed dropout layers in
conjuction with ReLU that proved to be very effective.

A brief descriotion of the fuctions of various AlexNet layers is provided
below:

\begin{itemize}
    \item Convolutional Layer puts the images from the previous layer through a
        set of convolutional filters which extract a particular feature;
    \item ReLU Layer maps negative values to zero which allows faster training
        while maintaining the positive ones;
    \item Pooling Layer performs downsampling, consequently, reduces the number
        of CNN parameters;
        \item Batch Normalization Layer speeds up training by normalizing each
            of the minibatches;
        \item Dropout Layer randomly sets the input elements to zero with a
            given probability and hence protects the network from overfitting;
        \item Fully Connected Layer identifies the larger patterns by combining
            all the features learned from the previous layers.
\end{itemize}

\subsubsection{ResNet}
A residual neural network (ResNet) is an artificial neural network (ANN) of a
kind that builds on constructs known from pyramidal cells in the cerebral
cortex \cite{Res}. They are typically built to overcome the vanishing gradient
problem of deep networks wherin the gradient becomes infinitively small due to
repeated backpropogations which typically leads to degradation of the
perfromance of the network. ResNet utilizes identity shortcut connection that
skips one or more layers, or shortcuts to jump over some layers. Typical ResNet
models are implemented with double- or triple- layer skips that contain
nonlinearities (ReLU) and batch normalization in between

\subsubsection{Transfer Learning}
Until the inception of transfer learning, conventional machine learning
approaches had been traditionally designed to work in isolation. They were
designed to solve a particular task and had to be rebuilt from scratch once the
feature space distribution changed. Transfer learning seeks to break this
notion of task specificity wherein the knowledge acquired from one task could
be utilized to solve another related one. Reusing a pretrained network as a
starting point to learn a new task is a commonly used transfer learning
approach.

An example of the use of transfer learning in image processing was made by
\cite{Ekat}. She had tested two different approaches with AlexNet to identify
Saimaa Ringed Seals from each other. Firstly, it has been used for the task of
segmenting the seal from its background. AlexNet is primarily used for feature
extraction in this case. The second application of AlexNet is in the
reidentification by means of the extarcted image patches of seal patterns. Once
again AlexNet is used for feature extraction. Followed by either retrainig the
exisiting CNN network or by means of an SVM classifier trained on the extracted
features. The results obtained were largely encouraging, about 90 percent of
the pictures were identified correctly. Although, SVM results were slightly
better.

\end{document}

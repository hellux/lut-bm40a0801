\documentclass[doc/report.tex]{subfiles}

% Describe the method which you have chosen for solving the task and explain
% why you have chosen this particular method.

\begin{document}

\section{Method}
A set of different classifiers were implemented using MatLab. In order to find
a good method, multiple methods and approaches were tested. How all of the
methods were implemented is described below in this chapter.

For some algorithms, existing built-in implementations of MatLab were used. In
these cases functions that were used are referenced.


\subsection{Preprocessing}
% TODO

\subsubsection{Data partitioning}
As the given dataset was already split into training and test sets, no further
partitioning was performed. The training set was used for training and the test
set was used for evaluation of the classifier. The number of each class from
each dataset is listed in table \ref{tbl:datasets}.

\begin{table}[h]
    \centering
    \begin{tabular}{l|rr|r}
        class & training & test & all \\\hline
        airplane    & 484   & 243   & 727 \\
        car         & 645   & 323   & 968 \\
        cat         & 590   & 295   & 885 \\
        dog         & 468   & 234   & 702 \\
        flower      & 562   & 281   & 843 \\
        fruit       & 667   & 333   & 1000 \\
        motorbike   & 525   & 263   & 788 \\
        person      & 658   & 328   & 986 \\\hline
        all         & 4599  & 2300  & 6899
    \end{tabular}
    \caption{Distribution of classes in datasets.}
    \label{tbl:datasets}
\end{table}

\subsubsection{Image augmentation}
Image augmentation was tested to see if it has a noticeable impact on the
accuracy of the classifier. Image augmentation was performed by adding random
variations of training samples to the training set using the
\texttt{augmentedImageDatastore}\footnote{https://www.mathworks.com/help/deeplearning/ref/augmentedimagedatastore.html}.
MatLab function. Variations that were used was horizontal reflections and
displacements in X and Y axes.

\subsection{Using Pre-Trained Network}
\subsubsection{Feature Extraction from Pretrained Networks}
By means of a pre-trained model that has been trained on similar datsets we can build a very accurate model without the hassle of the training the network in a timesaving manner. This is accomplished by extracting the image features from thetrainig set based on the patterns that have been learnt by these pre-trained network while solving a different problem rather than starting the learning process from scratch. This way, this method leverage previous learnings and avoid starting from scratch and saves time.  

\subsubsection{Transfer Learning Using AlexNet}

\subsection{Training Parameter Optimization}
\subsubsection{Batch Size and Training Epochs Tradeoff}
The size of mini-batches is the frequency of updates: the smaller the mini-batches the more will be the number of weight updates. As one would expect a single update with a big mini-batch is more accurate as compared to one with a small mini-batch. Moreover, bigger batches require lesser updates to reach the same level of accuracy. However, after the experimental evaluation it was observed that the smaller batches are preferable. This seems reasonable as smaller batches would imply smaller steps are taken towards convergence which in turn would minimize the chances of overshooting the optimal convergence point.

\subsubsection{Learing rate}
Learning rates of the network are one of the most influential parameters while training. Deep learning algorithms are trained using a stochastic gradient descent approaches like Adaptive Moment Optimization (ADAM), Root Mean Square Propogation (RMSProp), etc. The learning rate tells the optimizer how far to move the weights in the direction opposite to the gradient for a mini-batch. Low learning rates are reliable but require a large amount of training time as the steps needed to converge are very small. Large learning rates on the contrary are unreliable and generally converge quickly to suboptimal solutions.

One of the commonly used approaches is to start the training with a relatively large learning rate, since in the beginning random weights are far from optimal, then periodically reduce the learning rate after a specified number of epochs. That is why a piecewise learning rate schedule was used during the training phase.

\subsubsection{ADAM Optimizer}
The ADAM Optimizer was used instead of the stochastic gradient descent (SGD) for updating the weights of the network, since ADAM is straightforward to implement, computationally efficient, well suited for problems that are large in terms of data and parameters and its hyperparameters require little tuning.
% TODO
\subsection{Feature Extraction}

\subsubsection{Raw pixels}
One approach that was tested was to simply use raw pixel data as features. It
was done by converting the images to grayscale, resizing them to a fixed size
and concatenating all of the pixel intensities to a feature vector. The images
were resized to a size of 100x100 pixels resulting in 10000 features.

\subsubsection{Local Binary Patterns (LBP)}
Another feature vector that was used was Local Binary Patterns or LBP. It was
computed by resizing each image to e.g. 100x100 pixels and then converting it
into grayscale and dividing it into uniform cells, for example 10x10 pixels for
each cell.

And then for each cell; go through each pixel and calculate a number. The
number is calculated by comparing the 8 neighbouring pixels clockwise to the
pixel value. If the neighbour is larger or equal to the pixel then a 1 is
written to the number, otherwise a zero. The final number is then interpreted
as an 8-bit binary number. When the number for all pixels in the cell has been
computed, a normalized histogram vector is created from the distribution of
numbers within the cell. This is then performed for each cell and the final
result is a concatenation of all created histograms.

To achieve rotation invariance, the histogram bins were changed such that all
non-uniform numbers end up in the same bin, while each uniform number has its
own bin. Uniform numbers are numbers where the binary number transitions from 0
to 1 or 1 to 0 at most 2 times. For example "01000000" is uniform while
"01010101" is not.

\subsubsection{Speeded Up Robust Features (SURF)}
Speeded Up Robust Features or SURF was used as it is often useful for object
recognition.

SURF was extracted from the images by using the
\texttt{bagOfFeatures}\footnote{https://se.mathworks.com/help/vision/ref/bagoffeatures.html}
MatLab function. A bag of features was initially created with the training set.
A histogram of the features for each image was then created with the
\texttt{encode}\footnote{https://se.mathworks.com/help/vision/ref/bagoffeatures.encode.html}
function for both the training set and the test set using the inital bag of
features.




\subsection{Training and classification}
The task of classifying images based on the content is here approached with two
perspectives. Identify regions of the picture as a representation of some
object. The other is the comparing technical features of picture without
identification of objects in the picture. Such information is accessible from
the picture. A database of objects in the training set is needed for the other.

For classifying pictures based on objects they represent it is often needed to
normalize intensity information in them. Histogram equalization brings
properties of the objects more accessible and more independent from properties
of images.

To classify or cluster and classify images a method of comparing the vector of
image data with other vectors is sometimes used with neural net solutions like
CNN. To provide valid results, they are trained with a set of pictures. The net
is given response about the correctness of the answer for each of the training
pictures, and each picture is potentially used many times in the random order.
Values of features and regions evolve in the net without user directly
interfering. Other methods require more explicit information mining from the
picture.

\subsection{Feature extraction and region processing}
A region, an area in the picture, is sometimes an identifiable object in the
picture. Even if it is the goal to classify the main object of the picture,
sub-objects are often the handle for the class. For example, with the
information of the round objects the task of classification of the main object
is simplified. Convolutional networks do the process sometimes implicitly.

Generally, classification / training phase is faster or more accurate, if some
feature extraction is done to make the process specific for the task.

The color information, often Lab, grayscale intensities, statistical and
frequency level information are examples of features of the whole picture. They
are used for region analysis also.

To get regions or image segments it is he histograms first. From intensity
values of either color or grayscale, partitions separated from the rest, are
potential regions. A binary image is separated, outline i.e. border is
extracted. Remainder of the picture is returned to histogram and the process is
repeated.

Level sets and snakes are used to improve quality of the region. It is possible
to get watertight borderlines without noise by applying those methods.

Some candidates for the region features are convexity, cardinal line, normal
lines of cl, statistics of length of normal lines, skeleton of the region,
Area, length, width.

The boundary is one of the primary sources for the feature mining. Examples of
methods used with it are:

\begin{itemize}
    \item Chain Code, a vector of vectors describing segments of the boundary.
        With them many indicators of the region are possible. Area, height,
        width, cardinal lines and convexity are among possible results of the
        function with chain code as a parameter.
    \item Fourier descriptor, a complex valued vector about the boundary. It is
        used to identify, scale, rotate, and translate the boundary for the
        similarity measurement.
    \item Skeleton of the region. Middle lines of the region evaluated from the
        boundary. .
    \item The Hough transformation allows the search of ridges, curves and
        round or elliptical areas from the picture. Shapes and sizes are not
        limited.
    \item Morphological operators. Dilating and eroding binary images with
        different kernels. . For example, to extraction of outlines or reduced
        noise from the picture. Opening and closing operations combination of
        two main processing styles
\end{itemize}

Also, the background is potentially processed as a region. The Texture
information is also used as a feature. Use morphological operators and
frequency transformations are possible solutions to create selector for the
texture.


\subsection{Self Organizing Map}
The Self Organizing Map, SOM is a Neural Net model for dimension reduction.
From training material each picture is associated with a feature vector. Number
of pictures is the original dimension count and reduced dimension count is the
number of the classes of the pictures are representing, like cars, cats and so
on. For each class there is a weight vector in  the result space. The algorithm
starts random input vector. Euclidean distance is evaluated to each weight
vector, and nearest is considered the closest match. Weights of the feature
dimensions of the closest weight vector are adjusted to minimize the average
distance within the group.

In SOM map space is number of weight vectors with the dimensionality of input
vectors. In image processing dimensionality of the feature space. Weight
vectors represent classes similarly to KNN-clustering. When a new vector, i.e.
image is added to the system, Euclidean distances to weight vectors are
evaluated. Weights of the closest class are adjusted with a function
\eqref{eqn:som_w} to make the weight vector closer to the new vector.

\begin{equation}
    W_v(s+1) = W_v(s) + \theta(u, v, s) \cdot \alpha(s) \cdot (D(t) - W_v(s))
    \label{eqn:som_w}
\end{equation}

\begin{itemize}
    \item $W_v$: Weight vector closest to vector $v$
    \item $\theta$: Distance function giving distance from $u$ to $v$ in step
        $s$
    \item $\alpha$: Learning rate function, it gets smaller when the space size
        increases
    \item $D$: Input vector indexed with $t$
    \item $s$: step index
    \item $u$: index to best matching class vector
    \item $v$: index to a neuron in the goal space
\end{itemize}

\subsubsection{Support Vector Machine (SVM)}
% TODO

\subsubsection{Self-organizing map (SOM)}
Self-organizing maps were considered as they can provide a good visualization
of the classifier which can help to analyze and improve the classification.

Classification with SOM was performed by creating and training a
two-dimensional map using the training dataset according with help of the
MatLab functions
\texttt{selforgmap}\footnote{https://www.mathworks.com/help/deeplearning/ref/selforgmap.html}
and \texttt{train}. As the SOM is typically an unsupervised algorithm the
labels are not used while training the map. The labels are instead used
afterwards to determine what tile is considered what class.

Each tile of the map is considered to belong to the class that has most
classified samples for that tile. When classifying a new sample, it is placed
into a tile by using the SOM and then classified as the class of which that
tile belongs to.

The SOM has one parameter that was adjusted; the dimensions of the map. As the
problem has 8 classes the map must have at least 8 tiles to be able to
differentiate between all classes. But each class could also have more than one
tile as each class may have a set of subclasses. The dimensions was tested and
set as low as possible without losing accuracy as the higher dimension the
higher the training time is.

\end{document}
